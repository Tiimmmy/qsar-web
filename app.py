import os
import uuid
import re
import pandas as pd
import numpy as np
from rdkit import Chem
from rdkit.Chem import Descriptors, Lipinski, MolSurf, Crippen
from rdkit.Chem.QED import qed
from sklearn.linear_model import LogisticRegression
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import ConstantKernel, RBF, WhiteKernel
from sklearn.model_selection import KFold, StratifiedKFold
from sklearn.metrics import (
    r2_score, mean_absolute_error, mean_squared_error,
    accuracy_score, balanced_accuracy_score, roc_auc_score, roc_curve
)
from sklearn.preprocessing import StandardScaler
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
from flask import Flask, render_template, request, redirect, url_for



# ----------------------------
# åˆå§‹åŒ– Flask åº”ç”¨
# ----------------------------
app = Flask(__name__)
app.config['UPLOAD_FOLDER'] = 'uploads'
app.config['PLOT_FOLDER'] = 'static/plots'

os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)
os.makedirs(app.config['PLOT_FOLDER'], exist_ok=True)


# æè¿°ç¬¦è®¡ç®—å‡½æ•°ï¼ˆå®Œæ•´ç‰ˆï¼‰
def compute_all_descriptors(smiles_list, y_list):
    """
    è®¡ç®—æ‰€æœ‰ RDKit å†…ç½® + æ‰©å±•æè¿°ç¬¦
    
    å‚æ•°:
        smiles_list: List[str] - SMILES å­—ç¬¦ä¸²åˆ—è¡¨
        y_list: List[float] - å¯¹åº”æ´»æ€§å€¼ï¼ˆè¿ç»­æˆ–ç¦»æ•£ï¼‰
    
    è¿”å›:
        X: np.ndarray (n_samples, n_features) - æè¿°ç¬¦çŸ©é˜µ
        y: np.ndarray (n_samples,) - å¯¹é½åçš„æ´»æ€§å€¼
        valid_smiles: List[str] - æœ‰æ•ˆ SMILES
        desc_names: List[str] - æè¿°ç¬¦åç§°
    """
    # 1. æ ‡å‡†æè¿°ç¬¦ï¼ˆæ¥è‡ª Descriptors.descListï¼‰
    desc_names = []
    desc_funcs = []
    for name, func in Descriptors.descList:
        desc_names.append(name)
        desc_funcs.append(func)

    # 2. é¢å¤–æè¿°ç¬¦ï¼ˆå»é‡ï¼‰
    extra_descs = {
        'NumRotatableBonds': Lipinski.NumRotatableBonds,
        'FractionCSP3': Lipinski.FractionCSP3,
        'TPSA': MolSurf.TPSA,
        'MolMR': Crippen.MolMR,
        'QED': lambda m: qed(m)
    }

    for name, func in extra_descs.items():
        if name not in desc_names:
            desc_names.append(name)
            desc_funcs.append(func)

    print(f"ğŸ§ª ä½¿ç”¨ {len(desc_names)} ä¸ª RDKit æè¿°ç¬¦")

    # 3. è®¡ç®—æè¿°ç¬¦ï¼Œè¿‡æ»¤æ— æ•ˆåˆ†å­
    X = []
    valid_smiles = []
    valid_y = []

    for smi, y_val in zip(smiles_list, y_list):
        mol = Chem.MolFromSmiles(smi)
        if mol is None:
            continue
        try:
            # è®¡ç®—æ‰€æœ‰æè¿°ç¬¦
            desc_vals = [func(mol) for func in desc_funcs]
            # æ¸…æ´—ï¼šæ›¿æ¢ None / NaN / Inf ä¸º 0.0
            cleaned_vals = []
            for v in desc_vals:
                if v is None or np.isnan(v) or np.isinf(v):
                    cleaned_vals.append(0.0)
                else:
                    cleaned_vals.append(float(v))
            X.append(cleaned_vals)
            valid_smiles.append(smi)
            valid_y.append(y_val)
        except Exception as e:
            # å¯é€‰ï¼šè®°å½•é”™è¯¯åˆ†å­
            # print(f"âš ï¸ è·³è¿‡åˆ†å­ {smi}: {e}")
            continue

    if len(X) == 0:
        raise ValueError("âŒ æ²¡æœ‰æœ‰æ•ˆåˆ†å­å¯ç”¨äºå»ºæ¨¡")

    X = np.array(X, dtype=np.float32)
    y = np.array(valid_y, dtype=np.float32)

    print(f"âœ… æœ€ç»ˆæ•°æ®é›†: {X.shape[0]} åˆ†å­ Ã— {X.shape[1]} æè¿°ç¬¦")

    if X.shape[0] < 5:
        raise ValueError("âŒ æœ‰æ•ˆæ ·æœ¬å¤ªå°‘ï¼ˆ<5ï¼‰ï¼Œæ— æ³•å»ºæ¨¡")

    return X, y, valid_smiles, desc_names


# ----------------------------
# GPR å›å½’æ¨¡å‹å®šä¹‰
# ----------------------------
def create_conservative_gpr():
    kernel = (ConstantKernel(1.0, constant_value_bounds="fixed") *
              RBF(length_scale=22.0, length_scale_bounds="fixed") +
              WhiteKernel(noise_level=1.0, noise_level_bounds=(1e-2, 10)))
    return GaussianProcessRegressor(
        kernel=kernel,
        alpha=1e-2,
        normalize_y=True,
        random_state=42
    )

def train_gpr_regression(X, y):
    kf = KFold(n_splits=5, shuffle=True, random_state=42)
    
    gpr_train_r2s, gpr_val_r2s = [], []
    gpr_val_maes, gpr_val_rmses = [], []
    avg_uncertainties = []
    
    for train_idx, val_idx in kf.split(X):
        X_tr, X_val = X[train_idx], X[val_idx]
        y_tr, y_val = y[train_idx], y[val_idx]
        
        scaler = StandardScaler()
        X_tr_scaled = scaler.fit_transform(X_tr)
        X_val_scaled = scaler.transform(X_val)
        
        model = create_conservative_gpr()
        model.fit(X_tr_scaled, y_tr)
        
        y_pred_tr, sigma_tr = model.predict(X_tr_scaled, return_std=True)
        y_pred_val, sigma_val = model.predict(X_val_scaled, return_std=True)
        
        gpr_train_r2s.append(r2_score(y_tr, y_pred_tr))
        gpr_val_r2s.append(r2_score(y_val, y_pred_val))
        gpr_val_maes.append(mean_absolute_error(y_val, y_pred_val))
        gpr_val_rmses.append(np.sqrt(mean_squared_error(y_val, y_pred_val)))
        avg_uncertainties.append(np.mean(sigma_val))

    # å…¨é‡è®­ç»ƒç”¨äºç»˜å›¾
    scaler_full = StandardScaler()
    X_scaled_full = scaler_full.fit_transform(X)
    final_model = create_conservative_gpr()
    final_model.fit(X_scaled_full, y)
    y_pred_full, sigma_full = final_model.predict(X_scaled_full, return_std=True)

    return {
        'val_r2': np.mean(gpr_val_r2s),
        'mae': np.mean(gpr_val_maes),
        'rmse': np.mean(gpr_val_rmses),
        'avg_uncertainty': np.mean(avg_uncertainties),
        'y_true_plot': y,
        'y_pred_plot': y_pred_full,
        'sigma_plot': sigma_full,
        'n_samples': len(X)
    }


# ----------------------------
# åˆ†ç±»æ¨¡å‹
# ----------------------------
def train_classification(X, y_binary, desc_names):
    Cs = [0.1, 1.0, 10.0, 100.0]
    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
    best_bacc = -1
    best_C = 1.0

    for C in Cs:
        scores = []
        for train_idx, val_idx in skf.split(X, y_binary):
            X_tr, X_val = X[train_idx], X[val_idx]
            y_tr, y_val = y_binary[train_idx], y_binary[val_idx]
            scaler = StandardScaler()
            X_tr = scaler.fit_transform(X_tr)
            X_val = scaler.transform(X_val)
            model = LogisticRegression(penalty='l1', solver='liblinear', C=C, class_weight='balanced', max_iter=1000)
            model.fit(X_tr, y_tr)
            scores.append(balanced_accuracy_score(y_val, model.predict(X_val)))
        if np.mean(scores) > best_bacc:
            best_bacc = np.mean(scores)
            best_C = C

    all_y_true, all_y_proba = [], []
    accs, baccs, aucs = [], [], []

    for train_idx, val_idx in skf.split(X, y_binary):
        X_tr, X_val = X[train_idx], X[val_idx]
        y_tr, y_val = y_binary[train_idx], y_binary[val_idx]
        scaler = StandardScaler()
        X_tr = scaler.fit_transform(X_tr)
        X_val = scaler.transform(X_val)
        model = LogisticRegression(penalty='l1', solver='liblinear', C=best_C, class_weight='balanced', max_iter=1000)
        model.fit(X_tr, y_tr)
        y_pred = model.predict(X_val)
        y_proba = model.predict_proba(X_val)[:, 1]

        accs.append(accuracy_score(y_val, y_pred))
        baccs.append(balanced_accuracy_score(y_val, y_pred))
        aucs.append(roc_auc_score(y_val, y_proba))

        all_y_true.extend(y_val)
        all_y_proba.extend(y_proba)

    scaler_full = StandardScaler()
    X_scaled = scaler_full.fit_transform(X)
    final_model = LogisticRegression(penalty='l1', solver='liblinear', C=best_C, class_weight='balanced', max_iter=1000)
    final_model.fit(X_scaled, y_binary)
    coef = final_model.coef_[0]

    return {
        'acc': np.mean(accs),
        'bacc': np.mean(baccs),
        'auc': np.mean(aucs),
        'y_true': all_y_true,
        'y_proba': all_y_proba,
        'coef': coef,
        'desc_names': desc_names
    }


# ----------------------------
# ä¸»è·¯ç”±
# ----------------------------
@app.route('/', methods=['GET'])
def index():
    return render_template('index.html')

@app.route('/upload', methods=['POST'])
def upload():
    file = request.files.get('file')
    task = request.form.get('task_type', 'regression')
    if not file or not file.filename.endswith('.csv'):
        return "âŒ è¯·ä¸Šä¼  CSV æ–‡ä»¶", 400

    filename = f"{uuid.uuid4().hex}.csv"
    filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
    file.save(filepath)

    try:
        # ğŸ‘‡ è¯»å–å®Œæ•´ CSVï¼ˆä¸å†é™åˆ¶ 10 è¡Œï¼‰
        df_full = pd.read_csv(filepath)
        if len(df_full) > 5000:
            df_preview = df_full.head(5000)
            flash_message = "âš ï¸ æ–‡ä»¶è¾ƒå¤§ï¼Œä»…é¢„è§ˆå‰ 5000 è¡Œ"
        else:
            df_preview = df_full
            flash_message = None
    except Exception as e:
        return f"âŒ æ— æ³•è¯»å– CSV: {e}", 400

    # ä¼ é€’ç»™æ¨¡æ¿
    return render_template('file_preview.html',
                        filename=filename,
                        task=task,
                        columns=df_preview.columns.tolist(),
                        rows=df_preview.values.tolist(),
                        flash_message=flash_message)



@app.route('/start_training', methods=['POST'])
def start_training():
    filename = request.form['filename']
    task = request.form['task']

    try:
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        df = pd.read_csv(filepath)

        # è‡ªåŠ¨è¯†åˆ«åˆ—
        smiles_col = activity_col = None
        for col in df.columns:
            c = col.lower()
            if 'smile' in c: smiles_col = col
            if 'act' in c or 'value' in c or c in ['y', 'target', 'pic50']:
                activity_col = col
        if not smiles_col or not activity_col:
            return "âŒ åˆ—åéœ€åŒ…å« 'smile' å’Œ 'act'", 400

        # è§£ææ•°æ®
        data = []
        for _, row in df.iterrows():
            smi = str(row[smiles_col]).strip()
            act_str = str(row[activity_col]).strip()
            if smi in ('nan', '') or act_str in ('nan', ''): continue
            match = re.search(r'[-+]?\d*\.?\d+', act_str)
            if match:
                try:
                    y_val = float(match.group())
                    mol = Chem.MolFromSmiles(smi)
                    if mol is not None:
                        data.append((smi, y_val))
                except:
                    continue
        if len(data) < 5:
            return "âŒ æœ‰æ•ˆåˆ†å­å¤ªå°‘ï¼ˆè‡³å°‘éœ€è¦ 5 ä¸ªï¼‰", 400

        smiles_list, y_all = zip(*data)
        y_all = list(y_all)

        # è®¡ç®—æè¿°ç¬¦
        X, y_all, valid_smiles, desc_names = compute_all_descriptors(smiles_list, y_all)

        # è®­ç»ƒ
        if task == 'regression':
            if len(set(np.round(y_all, 6))) < 2:
                return "âŒ å›å½’ä»»åŠ¡éœ€è¦å˜åŒ–çš„æ´»æ€§å€¼", 400
            results = train_gpr_regression(X, y_all)

            plot_id = uuid.uuid4().hex
            sorted_idx = np.argsort(results['y_true_plot'])
            x_sorted = np.array(results['y_true_plot'])[sorted_idx]
            y_sorted = np.array(results['y_pred_plot'])[sorted_idx]
            sigma_sorted = np.array(results['sigma_plot'])[sorted_idx]

            plt.figure(figsize=(7, 6))
            plt.errorbar(x_sorted, y_sorted, yerr=sigma_sorted,
                         fmt='o', alpha=0.6, capsize=2, elinewidth=0.8, markersize=4)
            plt.plot([x_sorted.min(), x_sorted.max()], [x_sorted.min(), x_sorted.max()], 'r--', lw=1.5)
            plt.xlabel('True Activity')
            plt.ylabel('Predicted Activity')
            plt.title(f'GPR Regression (Val RÂ² = {results["val_r2"]:.2f})')
            plt.tight_layout()
            plot_path = f"{plot_id}_gpr_regression.png"
            plt.savefig(os.path.join(app.config['PLOT_FOLDER'], plot_path), dpi=150)
            plt.close()

            return render_template('regression_result.html',
                r2=results['val_r2'],
                mae=results['mae'],
                rmse=results['rmse'],
                avg_uncertainty=results['avg_uncertainty'],
                n_samples=results['n_samples'],
                plot_url=url_for('static', filename=f'plots/{plot_path}')
            )

        else:  # classification
            threshold = np.median(y_all)
            y_binary = (y_all >= threshold).astype(int)
            if len(set(y_binary)) < 2:
                return "âŒ åˆ†ç±»ä»»åŠ¡éœ€è¦ä¸¤ç±»æ ·æœ¬", 400
            results = train_classification(X, y_binary, desc_names)

            plot_id = uuid.uuid4().hex

            # æƒé‡å›¾
            plt.figure(figsize=(6, 4))
            colors = ['green' if w > 0 else 'red' for w in results['coef']]
            plt.barh(results['desc_names'], results['coef'], color=colors)
            plt.xlabel('Weight')
            plt.title('Key Descriptors (Green â†‘ / Red â†“)')
            plt.tight_layout()
            weight_plot = f"{plot_id}_weights.png"
            plt.savefig(os.path.join(app.config['PLOT_FOLDER'], weight_plot))
            plt.close()

            # ROC å›¾
            fpr, tpr, _ = roc_curve(results['y_true'], results['y_proba'])
            plt.figure(figsize=(5, 5))
            plt.plot(fpr, tpr, label=f'AUC = {results["auc"]:.2f}')
            plt.plot([0,1], [0,1], 'k--', alpha=0.5)
            plt.xlabel('FPR')
            plt.ylabel('TPR')
            plt.title('ROC Curve')
            plt.legend()
            plt.tight_layout()
            roc_plot = f"{plot_id}_roc.png"
            plt.savefig(os.path.join(app.config['PLOT_FOLDER'], roc_plot))
            plt.close()

            return render_template('classification_result.html',
                acc=results['acc'],
                bacc=results['bacc'],
                auc=results['auc'],
                threshold=threshold,
                n_samples=len(X),
                weight_plot=url_for('static', filename=f'plots/{weight_plot}'),
                roc_plot=url_for('static', filename=f'plots/{roc_plot}'),
                features=[{'desc': d, 'weight': w} for d, w in zip(results['desc_names'], results['coef'])]
            )

    except Exception as e:
        return f"âŒ è®­ç»ƒå¤±è´¥: {str(e)}", 500



if __name__ == '__main__':
    app.run(debug=True, host='127.0.0.1', port=5000)